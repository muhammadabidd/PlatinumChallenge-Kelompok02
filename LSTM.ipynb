{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>pilgub kemarin banyak boong nya , hasil nya di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>hti , wahabi , pks , fpi ikut2an menyerbu kiai...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>malas makan oreo , suka bikin gigi hitam</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lagi asik menonton di bioskop ada iklan pemeri...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>adeh . di mana letak muka nya itu orang . tida...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3440</th>\n",
       "      <td>3439.0</td>\n",
       "      <td>pkb benarkan charly setia band daftar jadi caw...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>3440.0</td>\n",
       "      <td>pernah percaya kalau body lotion citra bikin b...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>3441.0</td>\n",
       "      <td>bu susi marah , menteri luhut perbolehkan kapa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>3442.0</td>\n",
       "      <td>f - demokrat dorong upaya kemandirian energi n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>3443.0</td>\n",
       "      <td>hormati partai-partai yang telah berkoalisi</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3444 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                               text     label\n",
       "1        0.0  pilgub kemarin banyak boong nya , hasil nya di...  negative\n",
       "2        1.0  hti , wahabi , pks , fpi ikut2an menyerbu kiai...  negative\n",
       "3        2.0           malas makan oreo , suka bikin gigi hitam  negative\n",
       "4        3.0  lagi asik menonton di bioskop ada iklan pemeri...  negative\n",
       "5        4.0  adeh . di mana letak muka nya itu orang . tida...  negative\n",
       "...      ...                                                ...       ...\n",
       "3440  3439.0  pkb benarkan charly setia band daftar jadi caw...   neutral\n",
       "3441  3440.0  pernah percaya kalau body lotion citra bikin b...   neutral\n",
       "3442  3441.0  bu susi marah , menteri luhut perbolehkan kapa...   neutral\n",
       "3443  3442.0  f - demokrat dorong upaya kemandirian energi n...   neutral\n",
       "3444  3443.0        hormati partai-partai yang telah berkoalisi   neutral\n",
       "\n",
       "[3444 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataTrain/fixed_dataset.csv', header=None ).drop(0)\n",
    "df.columns=['index', 'text', 'label']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        index                                               text     label\n",
       "0        NaN                                               text     label\n",
       "1        0.0  pilgub kemarin banyak boong nya , hasil nya di...  negative\n",
       "2        1.0  hti , wahabi , pks , fpi ikut2an menyerbu kiai...  negative\n",
       "3        2.0           malas makan oreo , suka bikin gigi hitam  negative\n",
       "4        3.0  lagi asik menonton di bioskop ada iklan pemeri...  negative\n",
       "...      ...                                                ...       ...\n",
       "3440  3439.0  pkb benarkan charly setia band daftar jadi caw...   neutral\n",
       "3441  3440.0  pernah percaya kalau body lotion citra bikin b...   neutral\n",
       "3442  3441.0  bu susi marah , menteri luhut perbolehkan kapa...   neutral\n",
       "3443  3442.0  f - demokrat dorong upaya kemandirian energi n...   neutral\n",
       "3444  3443.0        hormati partai-partai yang telah berkoalisi   neutral\n",
       "\n",
       "[3445 rows x 3 columns]>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3444, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    1148\n",
       "positive    1148\n",
       "neutral     1148\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleansing(sent):\n",
    "    string = sent.lower()\n",
    "    string = re.sub(r'[^a-zA-Z0-9]', ' ', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df.text.apply(cleansing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>pilgub kemarin banyak boong nya , hasil nya di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>pilgub kemarin banyak boong nya   hasil nya di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>hti , wahabi , pks , fpi ikut2an menyerbu kiai...</td>\n",
       "      <td>negative</td>\n",
       "      <td>hti   wahabi   pks   fpi ikut2an menyerbu kiai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>malas makan oreo , suka bikin gigi hitam</td>\n",
       "      <td>negative</td>\n",
       "      <td>malas makan oreo   suka bikin gigi hitam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lagi asik menonton di bioskop ada iklan pemeri...</td>\n",
       "      <td>negative</td>\n",
       "      <td>lagi asik menonton di bioskop ada iklan pemeri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>adeh . di mana letak muka nya itu orang . tida...</td>\n",
       "      <td>negative</td>\n",
       "      <td>adeh   di mana letak muka nya itu orang   tida...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text     label  \\\n",
       "1    0.0  pilgub kemarin banyak boong nya , hasil nya di...  negative   \n",
       "2    1.0  hti , wahabi , pks , fpi ikut2an menyerbu kiai...  negative   \n",
       "3    2.0           malas makan oreo , suka bikin gigi hitam  negative   \n",
       "4    3.0  lagi asik menonton di bioskop ada iklan pemeri...  negative   \n",
       "5    4.0  adeh . di mana letak muka nya itu orang . tida...  negative   \n",
       "\n",
       "                                          text_clean  \n",
       "1  pilgub kemarin banyak boong nya   hasil nya di...  \n",
       "2  hti   wahabi   pks   fpi ikut2an menyerbu kiai...  \n",
       "3           malas makan oreo   suka bikin gigi hitam  \n",
       "4  lagi asik menonton di bioskop ada iklan pemeri...  \n",
       "5  adeh   di mana letak muka nya itu orang   tida...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = df.loc[df['label'] == 'negative'].text_clean.tolist()\n",
    "neu = df.loc[df['label'] == 'neutral'].text_clean.tolist()\n",
    "pos = df.loc[df['label'] == 'positive'].text_clean.tolist()\n",
    "\n",
    "neg_label = df.loc[df['label'] == 'negative'].label.tolist()\n",
    "neu_label = df.loc[df['label'] == 'neutral'].label.tolist()\n",
    "pos_label = df.loc[df['label'] == 'positive'].label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos: 1148, Neu: 1148, Neg: 1148\n",
      "Total data: 3444\n"
     ]
    }
   ],
   "source": [
    "total_data = pos + neu + neg\n",
    "labels = pos_label + neu_label + neg_label\n",
    "\n",
    "print(\"Pos: %s, Neu: %s, Neg: %s\" % (len(pos), len(neu), len(neg)))\n",
    "print(\"Total data: %s\" % len(total_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pickle has created!\n",
      "x_pad_sequences.pickle has created!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import defaultdict\n",
    "\n",
    "max_features = 100000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ', lower=True)\n",
    "tokenizer.fit_on_texts(total_data)\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"tokenizer.pickle has created!\")\n",
    "\n",
    "X = tokenizer.texts_to_sequences(total_data)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "maxlen = max(len(x) for x in X)\n",
    "\n",
    "X = pad_sequences(X)\n",
    "with open('x_pad_sequences.pickle', 'wb') as handle:\n",
    "    pickle.dump(X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"x_pad_sequences.pickle has created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_labels.pickle has created!\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(labels)\n",
    "Y = Y.values\n",
    "\n",
    "with open('y_labels.pickle', 'wb') as handle:\n",
    "    pickle.dump(Y, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"y_labels.pickle has created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "file = open(\"API/resources_of_lstm/x_pad_sequences.pickle\", 'rb')\n",
    "X = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open(\"API/resources_of_lstm/y_labels.pickle\", 'rb')\n",
    "Y = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, SimpleRNN, Activation\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 96, 100)           10000000  \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                42240     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,042,435\n",
      "Trainable params: 10,042,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "276/276 [==============================] - 40s 138ms/step - loss: 0.6799 - accuracy: 0.7125 - val_loss: 0.4463 - val_accuracy: 0.8258\n",
      "Epoch 2/10\n",
      "276/276 [==============================] - 38s 137ms/step - loss: 0.2721 - accuracy: 0.9027 - val_loss: 0.4789 - val_accuracy: 0.8316\n",
      "Epoch 3/10\n",
      "276/276 [==============================] - 37s 133ms/step - loss: 0.1018 - accuracy: 0.9670 - val_loss: 0.5028 - val_accuracy: 0.8258\n",
      "Epoch 4/10\n",
      "276/276 [==============================] - 37s 133ms/step - loss: 0.0467 - accuracy: 0.9869 - val_loss: 0.6480 - val_accuracy: 0.8171\n",
      "Epoch 5/10\n",
      "276/276 [==============================] - 37s 136ms/step - loss: 0.0325 - accuracy: 0.9902 - val_loss: 0.6649 - val_accuracy: 0.7983\n",
      "Epoch 6/10\n",
      "276/276 [==============================] - 37s 134ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.6657 - val_accuracy: 0.8113\n",
      "Epoch 7/10\n",
      "276/276 [==============================] - 37s 134ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.7736 - val_accuracy: 0.8142\n",
      "Epoch 8/10\n",
      "276/276 [==============================] - 37s 134ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.8637 - val_accuracy: 0.8113\n",
      "Epoch 9/10\n",
      "276/276 [==============================] - 37s 134ms/step - loss: 0.0375 - accuracy: 0.9873 - val_loss: 0.7679 - val_accuracy: 0.7910\n",
      "Epoch 10/10\n",
      "276/276 [==============================] - 37s 134ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.8515 - val_accuracy: 0.8070\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 100\n",
    "units = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim, input_length=X.shape[1]))\n",
    "model.add(LSTM(units, dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "adam = optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=10, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 10ms/step\n",
      "Testing selesai\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       232\n",
      "           1       0.88      0.84      0.86       218\n",
      "           2       0.79      0.85      0.82       239\n",
      "\n",
      "    accuracy                           0.81       689\n",
      "   macro avg       0.81      0.81      0.81       689\n",
      "weighted avg       0.81      0.81      0.81       689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = predictions\n",
    "matrix_test = metrics.classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print(\"Testing selesai\")\n",
    "print(matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 10ms/step\n",
      "Training ke- 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77       232\n",
      "           1       0.83      0.92      0.88       218\n",
      "           2       0.87      0.82      0.84       239\n",
      "\n",
      "    accuracy                           0.83       689\n",
      "   macro avg       0.83      0.83      0.83       689\n",
      "weighted avg       0.83      0.83      0.83       689\n",
      "\n",
      "======================================================\n",
      "22/22 [==============================] - 0s 10ms/step\n",
      "Training ke- 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       232\n",
      "           1       0.91      0.89      0.90       218\n",
      "           2       0.83      0.86      0.84       239\n",
      "\n",
      "    accuracy                           0.85       689\n",
      "   macro avg       0.85      0.85      0.85       689\n",
      "weighted avg       0.85      0.85      0.85       689\n",
      "\n",
      "======================================================\n",
      "22/22 [==============================] - 0s 10ms/step\n",
      "Training ke- 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80       232\n",
      "           1       0.86      0.93      0.90       218\n",
      "           2       0.84      0.87      0.85       239\n",
      "\n",
      "    accuracy                           0.85       689\n",
      "   macro avg       0.85      0.85      0.85       689\n",
      "weighted avg       0.85      0.85      0.85       689\n",
      "\n",
      "======================================================\n",
      "22/22 [==============================] - 1s 13ms/step\n",
      "Training ke- 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75       232\n",
      "           1       0.76      0.95      0.84       218\n",
      "           2       0.89      0.77      0.83       239\n",
      "\n",
      "    accuracy                           0.81       689\n",
      "   macro avg       0.81      0.81      0.81       689\n",
      "weighted avg       0.81      0.81      0.80       689\n",
      "\n",
      "======================================================\n",
      "22/22 [==============================] - 1s 13ms/step\n",
      "Training ke- 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80       232\n",
      "           1       0.88      0.92      0.90       218\n",
      "           2       0.83      0.87      0.85       239\n",
      "\n",
      "    accuracy                           0.85       689\n",
      "   macro avg       0.85      0.85      0.85       689\n",
      "weighted avg       0.85      0.85      0.85       689\n",
      "\n",
      "======================================================\n",
      "\n",
      "\n",
      "\n",
      "Rata-rata Accuracy:  0.8377358490566038\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5,random_state=42, shuffle=True)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "y = Y\n",
    "\n",
    "embed_dim = 100\n",
    "units = 64\n",
    "\n",
    "for iteration, data in enumerate(kf.split(X), start=1):\n",
    "\n",
    "    data_train   = X[data[0]]\n",
    "    target_train = y[data[0]]\n",
    "\n",
    "    data_test   = X[data[1]]\n",
    "    target_test = y[data[1]]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embed_dim, input_length=X.shape[1]))\n",
    "    model.add(LSTM(units, dropout=0.2))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "\n",
    "    adam = optimizers.Adam(learning_rate = 0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0)\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=10, validation_data=(X_test, y_test), verbose=0, callbacks=[es])\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    y_pred = predictions\n",
    "    accuracy = accuracy_score(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "    print(\"Training ke-\", iteration)\n",
    "    print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "    print(\"======================================================\")\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Rata-rata Accuracy: \", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     plt\u001b[39m.\u001b[39mlegend()\n\u001b[0;32m     23\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m plot_history(history)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "%matplotlib inline\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has created!\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')\n",
    "print(\"Model has created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from keras.models import load_model\n",
    "\n",
    "input_text = \"\"\"\n",
    "Rasa syukur, cukup.\n",
    "\"\"\"\n",
    "\n",
    "def cleansing(sent):\n",
    "\n",
    "    string = sent.lower()\n",
    "\n",
    "    string = re.sub(r'[^a-zA-Z0-9]', ' ', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 297ms/step\n",
      "Text:   rasa syukur  cukup  \n",
      "Sentiment:  negative\n"
     ]
    }
   ],
   "source": [
    "sentiment = ['negative', 'neutral', 'positive']\n",
    "\n",
    "text = [cleansing(input_text)]\n",
    "predicted = tokenizer.texts_to_sequences(text)\n",
    "guess = pad_sequences(predicted, maxlen=X.shape[1])\n",
    "\n",
    "model = load_model('API/resources_of_lstm/model.h5')\n",
    "prediction = model.predict(guess)\n",
    "polarity = np.argmax(prediction[0])\n",
    "\n",
    "print(\"Text: \",text[0])\n",
    "print(\"Sentiment: \",sentiment[polarity])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5d970ce3a869c424d840219ec304347cecc96c42e1b8d72b3facc8cee4d3a35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
